{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144592ad-b4d3-46fb-852f-ca7d3eb984a2",
   "metadata": {},
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b0b7c-e913-449b-9305-0fa56fc62227",
   "metadata": {},
   "source": [
    "1. Probability Mass Function (PMF):\n",
    "The PMF is used for discrete random variables. It gives the probability of each possible outcome of the random variable. The PMF assigns a probability value to each specific value that the random variable can take.\n",
    "\n",
    "##### Example: Let's consider a fair six-sided die. The random variable is the outcome of rolling the die. The PMF for this random variable would assign a probability value to each possible outcome from 1 to 6. Since the die is fair, each outcome has an equal probability of 1/6. So, the PMF would be:\n",
    "\n",
    "PMF(x) = 1/6 for x = 1, 2, 3, 4, 5, 6\n",
    "\n",
    "PMF(x) = 0   for other values of x\n",
    "\n",
    "2. Probability Density Function (PDF):\n",
    "The PDF is used for continuous random variables. It describes the probability distribution of a continuous random variable by specifying the probability density at each point in the range of the variable. Unlike the PMF, the PDF does not give the actual probability of a specific outcome, but rather the probability density at a given point.\n",
    "\n",
    "##### Example: Let's consider the height of adult females in a population. The random variable is the height. The PDF for this random variable would provide the probability density at each possible height value. For instance, the PDF might indicate that the probability density of heights around 160 cm is higher than the density around 170 cm. However, the PDF alone does not tell us the probability of a person having a specific height. To find the probability of a height falling within a particular range, we need to integrate the PDF over that range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af3656-25fa-48cd-9be2-fc3cd47d1619",
   "metadata": {},
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329e99d-3d63-4c9c-81ca-31d75dbe5b52",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a mathematical function that describes the probability that a random variable takes on a value less than or equal to a given value. In other words, the CDF gives the cumulative probability up to a certain point in the distribution.\n",
    "\n",
    "The CDF is denoted as F(x), where x is the value at which we want to evaluate the cumulative probability. The CDF is defined for both discrete and continuous random variables.\n",
    "\n",
    "Example: Let's consider a random variable X representing the number of heads obtained when flipping a fair coin three times. The possible values for X are 0, 1, 2, and 3. The CDF for this random variable would provide the cumulative probability for each possible value of X.\n",
    "\n",
    "To calculate the CDF, we sum up the probabilities from the PMF (Probability Mass Function) for all values less than or equal to the desired value. Here's the CDF for the random variable X:\n",
    "\n",
    "CDF(x) = P(X ≤ x)\n",
    "\n",
    "For X = 0: CDF(0) = P(X ≤ 0) = P(X = 0) = 1/8\n",
    "\n",
    "For X = 1: CDF(1) = P(X ≤ 1) = P(X = 0) + P(X = 1) = 1/8 + 3/8 = 4/8 = 1/2\n",
    "\n",
    "For X = 2: CDF(2) = P(X ≤ 2) = P(X = 0) + P(X = 1) + P(X = 2) = 1/8 + 3/8 + 3/8 = 7/8\n",
    "\n",
    "For X = 3: CDF(3) = P(X ≤ 3) = P(X = 0) + P(X = 1) + P(X = 2) + P(X = 3) = 1/8 + 3/8 + 3/8 + 1/8 = 1\n",
    "\n",
    "The CDF provides a range of information about the distribution of a random variable. It can be used to determine the probability of a random variable falling within a specific interval or to calculate percentiles. The CDF is particularly useful in statistical analysis and modeling, as it helps to understand the overall distribution and make predictions about the likelihood of certain events or outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc0ae1-1aa7-4ba9-a1db-763bc5cc20b1",
   "metadata": {},
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f984a79-2c2d-480b-8762-20667c945db8",
   "metadata": {},
   "source": [
    "#### The normal distribution, also known as the Gaussian distribution or bell curve, is a widely used probability distribution that describes many natural phenomena and random processes. It is characterized by its symmetric, bell-shaped curve and is defined by two parameters: the mean (μ) and the standard deviation (σ).\n",
    "\n",
    "Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "1. Heights of a Population: The heights of a large population tend to follow a normal distribution. The mean represents the average height, while the standard deviation determines the spread or variability in height among individuals.\n",
    "\n",
    "2. IQ Scores: Intelligence quotient (IQ) scores are often assumed to be normally distributed. The mean represents the average IQ score for a population, and the standard deviation indicates the variability in scores.\n",
    "\n",
    "3. Measurement Errors: In many scientific experiments or measurements, random errors can occur. These errors are often assumed to be normally distributed with a mean of zero and a certain standard deviation.\n",
    "\n",
    "4. Stock Market Returns: Daily or monthly returns of stock prices often exhibit a normal distribution. The mean represents the average return, while the standard deviation reflects the volatility or risk associated with the stock.\n",
    "\n",
    "The parameters\n",
    "\n",
    "1. Mean (μ): The mean determines the central location of the distribution. It represents the highest point of the bell curve and is also the average value of the random variable being modeled. Shifting the mean to the right or left changes the position of the peak of the curve.\n",
    "\n",
    "2. Standard Deviation (σ): The standard deviation determines the spread or dispersion of the distribution. A smaller standard deviation results in a narrower and taller curve, indicating less variability around the mean. Conversely, a larger standard deviation leads to a wider and flatter curve, indicating more dispersion in the data.\n",
    "\n",
    "By adjusting the mean and standard deviation, the normal distribution can be used to model a wide range of data, providing a useful framework for statistical analysis and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db9953-d0b3-4bf9-9152-e63cc0fab05a",
   "metadata": {},
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d85f7b-5917-439d-afd0-d8b8db986c98",
   "metadata": {},
   "source": [
    "#### Here are some reasons for the importance of the normal distribution:\n",
    "\n",
    "1. Central Limit Theorem: The normal distribution plays a central role in the Central Limit Theorem (CLT). According to the CLT, the sum or average of a large number of independent and identically distributed random variables tends to follow a normal distribution, regardless of the underlying distribution of the individual variables. This property allows researchers and statisticians to make inferences and perform hypothesis testing in a wide range of scenarios.\n",
    "\n",
    "2. Statistical Inference: Many statistical inference methods, such as confidence intervals and hypothesis tests, are based on the assumption of a normal distribution. When data approximately follows a normal distribution, it simplifies the analysis and allows for the use of powerful statistical techniques.\n",
    "\n",
    "3. Prediction and Modeling: The normal distribution is often used as a model for various real-life phenomena. It provides a convenient framework for describing and predicting the behavior of data. By estimating the mean and standard deviation of a normal distribution from observed data, we can make predictions about future values and quantify uncertainties.\n",
    "\n",
    "Real-life examples where the normal distribution is frequently observed include: Heights of Individuals,Test Scores, Measurement Errors, Stock Market Returns, also,\n",
    " \n",
    " Biological Traits: Characteristics such as birth weights, blood pressure, and cholesterol levels in a population often show a distribution that can be approximated by a normal distribution.\n",
    "\n",
    "Understanding and applying the normal distribution in these and other scenarios enables accurate modeling, analysis, and decision-making in various fields, including statistics, finance, economics, social sciences, and engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1049a95-00dc-4ead-a45b-ae5456dfc400",
   "metadata": {},
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2b8e4-8a1d-4f34-b921-ca783e626309",
   "metadata": {},
   "source": [
    "##### The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (usually represented by 1) and failure (usually represented by 0). It is named after Jacob Bernoulli, a Swiss mathematician. The distribution is characterized by a single parameter, often denoted as p, which represents the probability of success.\n",
    "\n",
    "Example of Bernoulli Distribution:\n",
    "Consider a coin toss, where success represents getting a \"heads\" and failure represents getting a \"tails.\" In this case, the Bernoulli distribution can be used to model the probability of obtaining a \"heads\" (success) with a certain coin. If the probability of getting a \"heads\" is p = 0.6, then the Bernoulli distribution can be represented as follows:\n",
    "\n",
    "P(X = 1) = 0.6 (probability of success)\n",
    "P(X = 0) = 0.4 (probability of failure)\n",
    "\n",
    "###### Difference:\n",
    "The Bernoulli distribution represents the success or failure of a single Bernoulli trial. The Binomial Distribution represents the number of successes and failures in n independent Bernoulli trials for some given value of n..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edb292-8666-451c-afcd-d60b9a12cfdd",
   "metadata": {},
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e52e72d-d83b-41d4-ae5c-cab5f1a84304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that a randomly selected observation will be greater than 60 is: 0.1587\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Given data\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "x = 60  # Value we want to calculate the probability for\n",
    "\n",
    "# Calculate the Z-score (standard score) for x\n",
    "z_score = (x - mean) / std_dev\n",
    "\n",
    "# Calculate the probability using the CDF of the standard normal distribution\n",
    "probability_greater_than_60 = 1 - stats.norm.cdf(z_score)\n",
    "\n",
    "print(f\"The probability that a randomly selected observation will be greater than 60 is: {probability_greater_than_60:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385d4d2-a739-402b-b2e6-6e8141467bac",
   "metadata": {},
   "source": [
    "## Q7: Explain Uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287863f1-4c4f-41ae-837d-765bbb77f432",
   "metadata": {},
   "source": [
    "#### The uniform distribution is a continuous probability distribution that describes a random variable where all values in a given range are equally likely to occur. In other words, the probability of any specific value occurring within the range is constant and uniform.\n",
    "\n",
    "The probability density function (PDF) of a uniform distribution is defined as follows:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "where 'a' is the lower bound of the range, 'b' is the upper bound of the range, and (b - a) is the width of the range.\n",
    "\n",
    "Example of Uniform Distribution:\n",
    "Let's consider a simple example of rolling a fair six-sided die. The outcome of rolling the die can be any value from 1 to 6. In this case, we can model the random variable X as the result of the die roll. Since the die is fair, each outcome is equally likely to occur.\n",
    "\n",
    "The uniform distribution for this example would be as follows:\n",
    "\n",
    "a = 1 (lower bound)\n",
    "b = 6 (upper bound)\n",
    "\n",
    "The probability density function (PDF) of the uniform distribution for this die roll would be:\n",
    "\n",
    "f(x) = 1 / (6 - 1) for 1 ≤ x ≤ 6\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "Here, f(x) is constant within the range of 1 to 6 and equal to 1/5, as the die has 6 possible outcomes, and each outcome has a probability of 1/6. This means that the probability of rolling any specific number on the fair die is 1/6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519c80c-054f-4090-938f-b3451af100ef",
   "metadata": {},
   "source": [
    "## Q8: What is the z score? State the importance of the z score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507386fd-ff34-4308-9330-cb551fcffb9b",
   "metadata": {},
   "source": [
    "##### The z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations a data point is away from the mean of a dataset. It is calculated by subtracting the mean from the data point and then dividing the result by the standard deviation. The formula for the z-score of a data point x in a dataset with mean μ and standard deviation σ is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "The z-score allows us to standardize data and compare individual data points to the overall distribution. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates it is below the mean. A z-score of 0 means the data point is exactly at the mean.\n",
    "\n",
    "The importance of the z-score can be summarized as follows:\n",
    "\n",
    "1. Standardization\n",
    "2. Outlier Detection\n",
    "3. Probability Calculation\n",
    "4. Hypothesis Testinge observed results to expected outcomes and make statistical conclusions.\n",
    "5. Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb4373-ae95-4f50-91d8-950938068ffb",
   "metadata": {},
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f1ca3-a63b-4305-901c-b913386167af",
   "metadata": {},
   "source": [
    "#### The Central Limit Theorem (CLT) is a fundamental theorem in statistics that states that the sampling distribution of the sample means of a large number of independent and identically distributed (i.i.d.) random variables will be approximately normally distributed, regardless of the shape of the original population's distribution.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "1. Sampling Distribution: The CLT allows us to understand the properties of the sample means even when we don't know the true population distribution. It tells us that, under certain conditions, the distribution of sample means will be normally distributed, centered around the true population mean, and with a standard deviation related to the population standard deviation and sample size.\n",
    "\n",
    "2. Estimation and Inference: The CLT is the foundation for many statistical methods, such as confidence intervals and hypothesis testing. It allows us to estimate population parameters and make inferences about the population based on sample data.\n",
    "\n",
    "3. Real-World Applications: The CLT has widespread applications in various fields, including quality control, market research, medical studies, and social sciences. It allows researchers to draw conclusions from limited data and make predictions about a population without having to know the underlying population distribution.\n",
    "\n",
    "In summary, the Central Limit Theorem is a powerful concept in statistics that enables us to make valid statistical inferences based on sample data, even when the underlying population distribution is unknown or non-normally distributed. Its significance lies in its practical applicability and its role in simplifying statistical analysis and hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496c271-b4ae-4232-a36b-43c58f34dc58",
   "metadata": {},
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da3ebe-eafd-4deb-8ec0-e3b6370fd330",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a powerful statistical theorem, but it comes with certain assumptions to hold true that are:\n",
    "\n",
    "1. Random Sampling: The data should be collected through a random sampling process, where each observation is chosen independently and without bias. Random sampling ensures that the sample is representative of the underlying population.\n",
    "\n",
    "2. Independence: The individual observations in the sample must be independent of each other. In other words, the value of one observation should not be influenced by or correlated with the values of other observations in the sample.\n",
    "\n",
    "3. Identically Distributed: The random variables in the sample must have the same probability distribution. This means that each observation is drawn from the same population and follows the same underlying distribution.\n",
    "\n",
    "4. Sufficiently Large Sample Size: The CLT applies when the sample size (n) is sufficiently large. While there is no strict cutoff, a common rule of thumb is that n should be greater than or equal to 30. However, in some cases, the CLT can still hold for smaller sample sizes if the underlying population is not heavily skewed or has extreme outliers.\n",
    "\n",
    "If these assumptions are met, the CLT ensures that the distribution of sample means will tend to be approximately normally distributed, centered around the true population mean, and with a standard deviation related to the population standard deviation and sample size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
